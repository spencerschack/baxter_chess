{"name":"Baxter chess","tagline":"Spencer Schack and Sam Friedman - UC Berkeley EE125 Fall 2014 Project","body":"# Introduction\r\nBaxter Chess allows humans to play chess against the Baxter robot on a physical chessboard. It’s been almost two decades since the Deep Blue computer defeated reigning world chess champion Garry Kasparov, but despite the sophistication of Deep Blue’s software, a human was still required to interpret the board state and physically execute moves. By incorporating sensing and robotic manipulation, Baxter Chess removes the operator middleman and allows humans to truly play a game of chess against a computer.\r\n\r\nThe work from this project can be adapted for any task in which a robot must interact with various objects in a grid formation, including playing other games, like checkers. More ambitious adaptations include monitoring and maintaining research, where the robot may have to observe an array of samples, and based on the observations perform some action. For example, Baxter may observe a grid of plants, and based on both the observed conditions of the plants and the rules of the experiment determine some action to perform on each sample. Also, the modelling involved around interpreting and manipulating a chess game can be applicable to many topics in robotics.\r\n\r\n# Design\r\nBaxter Chess must be able to interpret the state of the chessboard, including locating the chess pieces and identifying the correct player’s turn. It will use the board state to determine a reasonable (i.e. not random), legal move. Finally, the robot will execute that move accurately and without disturbing the locations of any other pieces. The robot must be able to execute all forms of legal chess moves, including attacks, castles, en passant, and promotion.\r\n\r\nBaxter Chess uses ARTags to track the locations of the board and chess pieces, and uses prior knowledge of the board dimensions to determine the board position of each piece. The open source Stockfish chess engine provides move selection. Baxter’s robotic arms are used to physically execute the move.\r\n\r\nStandard chess pieces are both difficult for Baxter to grasp, and too irregularly shaped for the application of the flat, square ARTags, so square blocks are used instead. Small pictures along the edges of the tag are used to identify the pieces to the human player, slightly reducing ease of use and aesthetic value. Additionally, the size of the board is limited by the range of Baxter’s arms, which in turn limits the size of the chess pieces. This limited size both decreases the robustness of the ARTags and requires a tighter margin of error for the movement of Baxter’s arms.\r\n\r\n# Implementation\r\nThe primary hardware component is the Baxter robot, with suction grippers. Baxter’s hand cameras observe the board and track the pieces. Additionally, Baxter Chess uses custom-made foam cubes with AR tags affixed to the top as pieces, and a white foam-core chessboard. The chessboard has square outlines drawn to assist the human player with visualizing board positions, but is otherwise left white to provide better contrast for Baxter’s cameras when tracking the AR tags.\r\n\r\n[ar_tags.pdf](https://github.com/spencerschack/baxter_chess/markers/ar_alvar_tags.pdf)\r\n\r\nThe software stack is built on ROS and incorporates many third party libraries, including Alvar AR tag tracker, MoveIt! path planning, Stockfish chess engine, and a python module to model the chess game. The AR tag tracker locates the chess pieces relative to a marker that is placed statically on the board next to the A1 square. These positions are then compared to the known size of the squares and used to construct the board state. After the board state is known and modeled, it is serialized and passed to the chess engine. When a move is received from the engine, it is parsed and analyzed to check for special cases such as attacking or castling. For a normal move, the right arm moves using a plan generated by MoveIt!. The arm is moved such that the camera on its hand is in a position right above the square the move is from. After receiving AR tag position updates to tell precisely where the piece is, the arm moves the suction cup down to the top of the piece and closes. The arm then moves over to a spot above the destination square and then moves down to drop the piece. For attacking moves, the left arm would pick the attacked piece and place it off to the side of the game, and then the right arm would continue as usual. For castling moves, the left arm held the castle in the suction cups while the right arm completed the move. After completing a move, the computer waits for human input to detect the next game state and make a move. To start the program, use the launch file which initializes the ar tag tracker, the inverse kinematics planner, the baxter interface, and the control node.\r\n\r\n# Results\r\nBaxter Chess performs well overall, but is limited by the both the precision of the robotic arms and the accuracy of the hand cameras with respect to tracking ARTags. In situations where Baxter can focus on a limited number of pieces located on a smaller subsection of the whole board, the robot can accurately detect the game state and execute moves. This is particularly well suited to endgames, where the robot was able to consistently beat the human player in testing. The robot can remove pieces from the board during attacks, and safely jump a knight over other pieces without disturbing them.\r\n\r\n<iframe width=\"560\" height=\"315\" src=\"//www.youtube.com/embed/xZvGHIRCyQE\" frameborder=\"0\" allowfullscreen></iframe>\r\n\r\n# Conclusion\r\nBaxter Chess performs well in limited-scope situations with a small number of pieces on a subset of the chessboard. The resolution and “fish-eye” effect of Baxter’s hand cameras prevented the robot from accurately identifying the board state when attempting to view the whole board. This obviously prevents Baxter from being able to play a full game of chess from start to finish. Given more time, we would have liked to explore adding additional high resolution cameras around the edge of the chessboard to improve the accuracy and reliability of the ARTag tracking.\r\n\r\nBaxter sometimes missed pieces when trying to pick them up with the suction cups due to inaccuracies in the arms. This was largely solved by slowing down Baxter’s arms, though this introduced occasional jerkiness in his movements and intermittent “Error Threshold Exceeded” errors that would require a program restart. With more time, we would find a more graceful solution to Baxter’s inaccuracies.\r\n\r\nFinally, promotion was not implemented, as the inaccuracy and unreliability of the ARTag tracking when attempting to view the whole board would have similarly limited Baxter’s ability to find the piece located to the side of the board that would replace the pawn.\r\n\r\n# Team\r\nSam Friedman is a senior in EECS. His academic and professional interests lie in control and embedded systems, with a focus on the interaction between digital systems and the physical world.\r\n\r\nSpencer Schack is in his last semester at Berkeley for EECS. His interests include user-experience design and robotics.\r\n\r\n# Additional Materials\r\nThe [GitHub Repository](https://github.com/spencerschack/baxter_chess) contains all code, launch files, and ar tag images.","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}